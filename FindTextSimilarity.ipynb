{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"search mail\", \"read mail\",\"send mail\",\"Go back\",\"Search mails by name\",\"starred mails\",\"unread mails\",\"full inbox\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "\n",
    "# initialize dictionary that will contain tokenized sentences\n",
    "tokens = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "for sentence in sentences:\n",
    "    # tokenize sentence and append to dictionary lists\n",
    "    new_tokens = tokenizer.encode_plus(sentence, max_length=128, truncation=True,\n",
    "                                       padding='max_length', return_tensors='pt')\n",
    "    tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "    tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "\n",
    "# reformat list of tensors into single tensor\n",
    "tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "tokens['attention_mask'] = torch.stack(tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**tokens)\n",
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3942,  0.3029,  1.4472,  ...,  0.0101,  0.0862,  0.0922],\n",
       "         [-0.2035,  0.6168,  2.0040,  ..., -0.3405,  0.0207, -0.0964],\n",
       "         [ 0.0917,  0.4722,  1.3937,  ..., -0.1057, -0.0399, -0.2460],\n",
       "         ...,\n",
       "         [ 0.0147,  0.2153,  1.2861,  ..., -0.2732, -0.0982, -0.0100],\n",
       "         [-0.2540, -0.0648,  1.1406,  ...,  0.0134, -0.0648, -0.2483],\n",
       "         [-0.1354,  0.0121,  1.1041,  ..., -0.0334, -0.1695, -0.1625]],\n",
       "\n",
       "        [[-0.2258, -0.0273,  1.1741,  ...,  0.9997,  0.0922, -0.2964],\n",
       "         [-0.2618,  0.2790,  1.5802,  ...,  0.6187,  0.0968, -0.4657],\n",
       "         [ 0.0254,  0.0281,  1.3444,  ...,  0.6779, -0.1042, -0.3806],\n",
       "         ...,\n",
       "         [ 0.0717, -0.0417,  1.2423,  ...,  0.5344, -0.0085, -0.1196],\n",
       "         [-0.1413, -0.2517,  0.9939,  ...,  0.7855, -0.0623, -0.3433],\n",
       "         [-0.0742, -0.0685,  1.0065,  ...,  0.5816, -0.2019, -0.1838]],\n",
       "\n",
       "        [[-0.0521, -0.0542,  1.1683,  ...,  0.7507, -0.3254, -0.0666],\n",
       "         [ 0.1002,  0.1243,  1.8430,  ...,  0.4540, -0.2852, -0.3249],\n",
       "         [ 0.2873,  0.0434,  1.3416,  ...,  0.5366, -0.2578, -0.2207],\n",
       "         ...,\n",
       "         [ 0.2063, -0.0929,  1.3022,  ...,  0.3641, -0.1938, -0.0867],\n",
       "         [-0.0558, -0.4135,  0.8834,  ...,  0.6383, -0.2931, -0.2934],\n",
       "         [-0.0180, -0.2603,  0.9281,  ...,  0.5302, -0.3245, -0.1690]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0709, -0.1541,  1.2542,  ..., -0.0721,  0.1810, -0.4276],\n",
       "         [ 0.3161,  0.2508,  1.3043,  ..., -0.3538, -0.0532, -0.8131],\n",
       "         [ 0.5352, -0.1008,  0.9501,  ..., -0.1259,  0.1059, -0.6066],\n",
       "         ...,\n",
       "         [ 0.1890,  0.0073,  1.0566,  ..., -0.2555,  0.0129, -0.4959],\n",
       "         [ 0.1449, -0.0133,  0.6963,  ..., -0.1912, -0.0428, -0.5401],\n",
       "         [-0.0241, -0.2089,  0.7499,  ..., -0.0551, -0.0032, -0.6197]],\n",
       "\n",
       "        [[ 0.0930,  0.2946,  0.9528,  ...,  0.1389, -0.2429, -0.1119],\n",
       "         [ 0.0314,  0.2886,  0.5073,  ..., -0.0561, -0.4871, -0.4662],\n",
       "         [-0.0059,  0.8872,  1.1054,  ..., -0.0193, -0.6497, -1.1204],\n",
       "         ...,\n",
       "         [-0.0557,  0.0435,  0.5069,  ...,  0.1418, -0.4834,  0.1436],\n",
       "         [ 0.0319,  0.0648,  0.4458,  ...,  0.0456, -0.4606, -0.0853],\n",
       "         [ 0.0584,  0.0618,  0.6112,  ..., -0.0457, -0.4354, -0.1140]],\n",
       "\n",
       "        [[-0.7749, -0.4463,  0.5696,  ...,  0.2808, -0.0983, -0.0567],\n",
       "         [-0.4918, -0.2187,  0.3259,  ...,  0.0482, -0.0223, -0.5166],\n",
       "         [-0.4289, -0.2385, -0.0485,  ..., -0.2320, -0.0580, -0.0950],\n",
       "         ...,\n",
       "         [-0.3983, -0.0096,  0.3449,  ...,  0.1178, -0.3148, -0.0446],\n",
       "         [-0.3636, -0.0292,  0.1949,  ..., -0.0474, -0.2964, -0.1277],\n",
       "         [-0.6256, -0.3831,  0.4074,  ...,  0.3141, -0.1783, -0.3440]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = outputs.last_hidden_state\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128, 768])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = tokens['attention_mask']\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128, 768])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128, 768])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings = embeddings * mask\n",
    "masked_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3942,  0.3029,  1.4472,  ...,  0.0101,  0.0862,  0.0922],\n",
       "         [-0.2035,  0.6168,  2.0040,  ..., -0.3405,  0.0207, -0.0964],\n",
       "         [ 0.0917,  0.4722,  1.3937,  ..., -0.1057, -0.0399, -0.2460],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
       "\n",
       "        [[-0.2258, -0.0273,  1.1741,  ...,  0.9997,  0.0922, -0.2964],\n",
       "         [-0.2618,  0.2790,  1.5802,  ...,  0.6187,  0.0968, -0.4657],\n",
       "         [ 0.0254,  0.0281,  1.3444,  ...,  0.6779, -0.1042, -0.3806],\n",
       "         ...,\n",
       "         [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000]],\n",
       "\n",
       "        [[-0.0521, -0.0542,  1.1683,  ...,  0.7507, -0.3254, -0.0666],\n",
       "         [ 0.1002,  0.1243,  1.8430,  ...,  0.4540, -0.2852, -0.3249],\n",
       "         [ 0.2873,  0.0434,  1.3416,  ...,  0.5366, -0.2578, -0.2207],\n",
       "         ...,\n",
       "         [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0709, -0.1541,  1.2542,  ..., -0.0721,  0.1810, -0.4276],\n",
       "         [ 0.3161,  0.2508,  1.3043,  ..., -0.3538, -0.0532, -0.8131],\n",
       "         [ 0.5352, -0.1008,  0.9501,  ..., -0.1259,  0.1059, -0.6066],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
       "         [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
       "\n",
       "        [[ 0.0930,  0.2946,  0.9528,  ...,  0.1389, -0.2429, -0.1119],\n",
       "         [ 0.0314,  0.2886,  0.5073,  ..., -0.0561, -0.4871, -0.4662],\n",
       "         [-0.0059,  0.8872,  1.1054,  ..., -0.0193, -0.6497, -1.1204],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
       "\n",
       "        [[-0.7749, -0.4463,  0.5696,  ...,  0.2808, -0.0983, -0.0567],\n",
       "         [-0.4918, -0.2187,  0.3259,  ...,  0.0482, -0.0223, -0.5166],\n",
       "         [-0.4289, -0.2385, -0.0485,  ..., -0.2320, -0.0580, -0.0950],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 768])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed = torch.sum(masked_embeddings, 1)\n",
    "summed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 768])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "summed_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 4., 4.,  ..., 4., 4., 4.],\n",
       "        [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "        [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "        ...,\n",
       "        [5., 5., 5.,  ..., 5., 5., 5.],\n",
       "        [7., 7., 7.,  ..., 7., 7., 7.],\n",
       "        [5., 5., 5.,  ..., 5., 5., 5.]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pooled = summed / summed_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2447,  0.5197,  1.7501,  ..., -0.0472, -0.0622, -0.0422],\n",
       "        [-0.2232,  0.0823,  1.5360,  ...,  0.8506, -0.0146, -0.3242],\n",
       "        [ 0.0622,  0.0731,  1.6312,  ...,  0.6340, -0.3536, -0.1498],\n",
       "        ...,\n",
       "        [ 0.1445, -0.1180,  1.3465,  ..., -0.1240,  0.0778, -0.5535],\n",
       "        [ 0.0913,  0.4663,  0.9869,  ...,  0.0653, -0.4017, -0.4818],\n",
       "        [-0.5792, -0.2039,  0.4067,  ...,  0.0853, -0.0118, -0.1104]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7906319 , 0.8302841 , 0.4992538 , 0.81634897, 0.61364186,\n",
       "        0.6586647 , 0.49970666]], dtype=float32)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled = mean_pooled.detach().numpy()\n",
    "\n",
    "# calculate\n",
    "cosine_similarity(\n",
    "    [mean_pooled[0]],\n",
    "    mean_pooled[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
